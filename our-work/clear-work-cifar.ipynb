{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from mlfunctions import MNISTNet, cache, do_fit,fit_optimizer, MNISTLoss, w, Optimizer\n",
    "import numpy as np\n",
    "import torch.optim as optim\n",
    "import glob\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.autograd as autograd\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "import multiprocessing\n",
    "import os.path\n",
    "import csv\n",
    "import copy\n",
    "import joblib\n",
    "from torchvision import datasets\n",
    "import torchvision\n",
    "import seaborn as sns; sns.set(color_codes=True)\n",
    "sns.set_style(\"white\")\n",
    "from pdb import set_trace as bp\n",
    "from meta_module import MetaLinear, MetaModule,MetaConv2d,MetaConvTranspose2d, MetaBatchNorm2d\n",
    "import functools\n",
    "\n",
    "from torchsummary import summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "source": [
    "## CIFAR-10 training \n",
    "\n",
    "First, change the optimizer structure using the MetaConv2D. "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CIFAR10Loss:\n",
    "    def __init__(self, training=True):\n",
    "        dataset = datasets.CIFAR10(\n",
    "            '.\\ourwork\\data', train=True, download=False,\n",
    "            transform=torchvision.transforms.ToTensor()\n",
    "        )\n",
    "        indices = list(range(len(dataset)))\n",
    "        np.random.RandomState(10).shuffle(indices)\n",
    "        if training:\n",
    "            indices = indices[:len(indices) // 2]\n",
    "        else:\n",
    "            indices = indices[len(indices) // 2:]\n",
    "\n",
    "        self.loader = torch.utils.data.DataLoader(\n",
    "            dataset, batch_size=128,\n",
    "            sampler=torch.utils.data.sampler.SubsetRandomSampler(indices))\n",
    "\n",
    "        self.batches = []\n",
    "        self.cur_batch = 0\n",
    "        \n",
    "    def sample(self):\n",
    "        if self.cur_batch >= len(self.batches):\n",
    "            self.batches = []\n",
    "            self.cur_batch = 0\n",
    "            for b in self.loader:\n",
    "                self.batches.append(b)\n",
    "        batch = self.batches[self.cur_batch]\n",
    "        self.cur_batch += 1\n",
    "        return batch\n",
    "\n",
    "class CIFAR10Net(MetaModule):\n",
    "\n",
    "    def __init__(self, layer_size=32, n_layers=3, **kwargs):\n",
    "        super().__init__()\n",
    "\n",
    "\n",
    "        # add linear layers \n",
    "        \n",
    "        # for i in range(n_layers):\n",
    "        #     self.layers[f'mat_{i}'] = MetaLinear(inp_size, layer_size)\n",
    "        #     inp_size = layer_size\n",
    "\n",
    "        self.layers = {}\n",
    "        # Main layers (Convolutions + MaxPooling)\n",
    "        in_channels = 3\n",
    "        self.hidden_channels = [3,5,8,16]\n",
    "\n",
    "        for i in range(1,n_layers+1):\n",
    "            self.layers[f'conv_{i}'] = MetaConv2d(in_channels, self.hidden_channels[i], kernel_size=3)\n",
    "            self.layers[f'norm_{i}'] = nn.BatchNorm2d(self.hidden_channels[i-1], affine=False, track_running_stats=False)\n",
    "            in_channels = self.hidden_channels[i]\n",
    "\n",
    "        self.activation = nn.ReLU()\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2,)\n",
    "        \n",
    "\n",
    "        # Linear Layers \n",
    "        self.layers['linear'] = MetaLinear(16*2*2 , layer_size)\n",
    "\n",
    "        self.layers = nn.ModuleDict(self.layers)\n",
    "\n",
    "        self.loss = nn.NLLLoss()\n",
    "\n",
    "    def all_named_parameters(self):\n",
    "        return [(k, v) for k, v in self.named_parameters()]\n",
    "    \n",
    "    def forward(self, loss):\n",
    "        inp, out = loss.sample()\n",
    "        inp = w(Variable(inp.view(inp.size()[0], 3,32,32)))    # reshapes from inp.shape\n",
    "        out = w(Variable(out))\n",
    "\n",
    "\n",
    "        for cur_layer in range(1,4):    #since the layers are defined from 1...\n",
    "            # print(\"Shape before conv2D - kernel = 3 \\t\" + str(inp.shape))\n",
    "            inp = self.layers[f'norm_{cur_layer}'](inp)    #affine = False makes the batch nor parameters not-learnable (keep it simple)\n",
    "            inp = self.layers[f'conv_{cur_layer}'](inp)\n",
    "            inp = self.pool(inp)\n",
    "            inp = self.activation(inp)\n",
    "            \n",
    "            cur_layer += 1\n",
    "            \n",
    "        # print(\"Shape after CNN \\t\" + str(inp.shape))\n",
    "        # inp = inp.view(-1, 16*2*2)  # flatten\n",
    "        inp = torch.flatten(inp,start_dim=1)\n",
    "        \n",
    "        inp = F.log_softmax(self.layers['linear'](inp), dim=1)\n",
    "\n",
    "        #debugging....\n",
    "        # print(inp.shape,out.shape)\n",
    "        l = self.loss(inp, out)\n",
    "\n",
    "        return l"
   ]
  },
  {
   "source": [
    "After the optmizee is done, we re-build the optmizer with athe new architecture: 2 LSTMs in series - one forthe conv2Dand one for the lienear (i.e.) fully connected. "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class Optimizer(nn.Module):\n",
    "    def __init__(self, preproc=False, hidden_sz=20, preproc_factor=10.0):\n",
    "        super().__init__()\n",
    "        self.hidden_sz = hidden_sz\n",
    "        if preproc:\n",
    "            self.recurs = nn.LSTMCell(2, hidden_sz)\n",
    "        else:\n",
    "            self.recurs = nn.LSTMCell(1, hidden_sz)\n",
    "        self.recurs2 = nn.LSTMCell(hidden_sz, hidden_sz)\n",
    "        self.output = nn.Linear(hidden_sz, 1)\n",
    "        self.preproc = preproc\n",
    "        self.preproc_factor = preproc_factor\n",
    "        self.preproc_threshold = np.exp(-preproc_factor)\n",
    "\n",
    "    def forward(self, inp, hidden, cell):\n",
    "        if self.preproc:\n",
    "            # Implement preproc described in Appendix A\n",
    "\n",
    "            # Note: we do all this work on tensors, which means\n",
    "            # the gradients won't propagate through inp. This\n",
    "            # should be ok because the algorithm involves\n",
    "            # making sure that inp is already detached.\n",
    "            inp = inp.data\n",
    "            inp2 = w(torch.zeros(inp.size()[0], 2))\n",
    "            keep_grads = (torch.abs(inp) >= self.preproc_threshold).squeeze()\n",
    "            inp2[:, 0][keep_grads] = (torch.log(torch.abs(inp[keep_grads]) + 1e-8) / self.preproc_factor).squeeze()\n",
    "            inp2[:, 1][keep_grads] = torch.sign(inp[keep_grads]).squeeze()\n",
    "\n",
    "            inp2[:, 0][~keep_grads] = -1\n",
    "            inp2[:, 1][~keep_grads] = (float(np.exp(self.preproc_factor)) * inp[~keep_grads]).squeeze()\n",
    "            inp = w(Variable(inp2))\n",
    "        hidden0, cell0 = self.recurs(inp, (hidden[0], cell[0]))\n",
    "        hidden1, cell1 = self.recurs2(hidden0, (hidden[1], cell[1]))\n",
    "        \n",
    "        return self.output(hidden1), (hidden0, hidden1), (cell0, cell1)\n"
   ]
  },
  {
   "source": [
    "Now let's try to fit CIFAR classifier."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "@cache.cache\n",
    "def get_fit_dict_test(n_tests, opt_dict, *args, **kwargs):\n",
    "    opt = w(Optimizer(preproc=True))\n",
    "    opt.load_state_dict(opt_dict)\n",
    "    np.random.seed(0)\n",
    "    return [do_fit(opt, *args, **kwargs) for _ in tqdm(range(N_TESTS), 'optimizer')]\n",
    "\n",
    "\n",
    "@cache.cache\n",
    "def fit_normal(target_cls, target_to_opt, opt_class, n_tests=100, n_epochs=100, **kwargs):\n",
    "    results = []\n",
    "    for i in tqdm(range(n_tests), 'tests'):\n",
    "        target = target_cls(training=False)\n",
    "        optimizee = w(target_to_opt())\n",
    "        optimizer = opt_class(optimizee.parameters(), **kwargs)\n",
    "        total_loss = []\n",
    "        for _ in range(n_epochs):\n",
    "            loss = optimizee(target)\n",
    "            \n",
    "            total_loss.append(loss.data.cpu().numpy())\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        results.append(total_loss)\n",
    "\n",
    "        \n",
    "    return results"
   ]
  },
  {
   "source": [
    "Optimizer training is done here (this is the one that takes a while):"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "epochs:   0%|          | 0/20 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "615a78574590450a96d10ff087a1de26"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "iterations:   0%|          | 0/20 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "534c6c1274be47bf8ac65849fe74494c"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "tests:   0%|          | 0/20 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "456feee837204cc389d4e42fd95fb7da"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "192.491\n100000000000000000 192.491\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "iterations:   0%|          | 0/20 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "b9c7a21ab45748bbb2e210e34c980fde"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "tests:   0%|          | 0/20 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "3ddd2eeb03bc41d6992388ce4c8ca2c9"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "201.97897\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "iterations:   0%|          | 0/20 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "7b7c5f07091646c29b75078f774747ca"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "tests:   0%|          | 0/20 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "4109dab042f84192856632e054b60523"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "188.1811\n192.491 188.1811\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "iterations:   0%|          | 0/20 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "4a7eec78375340d9b27c9a11a7461f7b"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "tests:   0%|          | 0/20 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "26ff3d10879a4c399e6cd680409bf06d"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "185.90854\n188.1811 185.90854\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "iterations:   0%|          | 0/20 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "6dc537875ef04f58aa2a671bd430666e"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "tests:   0%|          | 0/20 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "d903010a014a4d71bf844cf0e9758083"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "193.98254\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "iterations:   0%|          | 0/20 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "2a58bcea0551468284a8a37313205088"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "tests:   0%|          | 0/20 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "6a689dea909c465db6a4779cf5e0a039"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "188.1539\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "iterations:   0%|          | 0/20 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "bfddfb24c9e24e9e977fb5f486ae34b6"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "tests:   0%|          | 0/20 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "0f22e491157b42c7be7852f865d10099"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "186.3597\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "iterations:   0%|          | 0/20 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "85a4b66f7fc94d11aaab8b263212248d"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "tests:   0%|          | 0/20 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "487e8f9def2246eeaea1e11411a5984f"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "191.22554\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "iterations:   0%|          | 0/20 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "2ef26ece43bb4efcb32d3a2dcbc5dc58"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "tests:   0%|          | 0/20 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "90b547d350b64a02ab2e58392cd3199d"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "187.33469\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "iterations:   0%|          | 0/20 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "623095e942534bff94175298b568c009"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "tests:   0%|          | 0/20 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "7e932d421976476cbe6e6537b754bca4"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "187.4566\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "iterations:   0%|          | 0/20 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "506ae202878846cd942d27e7e832f99b"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "tests:   0%|          | 0/20 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "276286231c1e4c0b9588d409091604f3"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "193.65115\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "iterations:   0%|          | 0/20 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "87f8a2c1cb454534a10f88fcda4f7ea4"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "tests:   0%|          | 0/20 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "bf8323b7c59b44729d39a663299bc2d1"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "187.57411\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "iterations:   0%|          | 0/20 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "86e24a25bcf74b06ac0a453ba3d335be"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "tests:   0%|          | 0/20 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "d4abbfbc4c74480188279c2c574947d7"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "183.25851\n185.90854 183.25851\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "iterations:   0%|          | 0/20 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "366ca5a25de14722af17cbcfd36c822e"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "tests:   0%|          | 0/20 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "3868d3bc39d0480eabedba0d67f2ea7b"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "182.86383\n183.25851 182.86383\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "iterations:   0%|          | 0/20 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "e9a85778ac5147efb07848a56f2266d8"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "tests:   0%|          | 0/20 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "ed9fa8f974154a589b603603a8468a42"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "184.34518\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "iterations:   0%|          | 0/20 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "9a70a3fc3dfb4872be79160ba1bd9394"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "tests:   0%|          | 0/20 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "f966f598fbf14bc7bd3063f0a2ecb228"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "180.76376\n182.86383 180.76376\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "iterations:   0%|          | 0/20 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "2a3f2062798f48349be1927a0d1d0daa"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "tests:   0%|          | 0/20 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "a93cbd177a834748bdd83f3430ad4ca6"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "185.6484\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "iterations:   0%|          | 0/20 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "72d80fb81bba44ec8dfb962b5c673e1a"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "tests:   0%|          | 0/20 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "3e8768d721584c91827926269dcaa14f"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "178.5332\n180.76376 178.5332\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "iterations:   0%|          | 0/20 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "ada563aeb00d4a12abb08ed380ac037b"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "tests:   0%|          | 0/20 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "967070b2067d4ed7897479aadc0b920f"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "177.83179\n178.5332 177.83179\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "iterations:   0%|          | 0/20 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "a9aa75a425ce45b8a30042f5024218fe"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "tests:   0%|          | 0/20 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "a919309d394c480e83b93fc14b82a91c"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "177.16946\n177.83179 177.16946\n"
     ]
    }
   ],
   "source": [
    "# for lr in tqdm(sorted([1.0, 0.3, 0.1, 0.03, 0.01, 0.003, 0.001, 0.0003, 0.0001, 0.00003, 0.00001], key=lambda x: np.abs(x - 0.003)), 'all'):\n",
    "#     print('Trying lr:', lr)\n",
    "\n",
    "loss, cifar10_optimizer = fit_optimizer(CIFAR10Loss, CIFAR10Net, lr=0.03,  n_epochs=20, n_tests=20, out_mul=0.1, preproc=True)\n",
    "\n"
   ]
  },
  {
   "source": [
    "@cache.cache\n",
    "def get_fit_dict_test(n_tests, opt_dict, *args, **kwargs):\n",
    "    opt = w(Optimizer(preproc=True))\n",
    "    opt.load_state_dict(opt_dict)\n",
    "    np.random.seed(0)\n",
    "    return [do_fit(opt, *args, **kwargs) for _ in tqdm(range(N_TESTS), 'optimizer')]\n",
    "\n",
    "\n",
    "fit_data[:, :, len(OPT_NAMES)] = np.array(get_fit_dict_test(N_TESTS, mnist_optimizer, None, MNISTLoss, MNISTNet, 1, 200, 200, out_mul=0.1, should_train=False))"
   ],
   "cell_type": "code",
   "metadata": {},
   "execution_count": 51,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "747.4585"
      ]
     },
     "metadata": {},
     "execution_count": 51
    }
   ]
  },
  {
   "source": [
    "Save the trained model:"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "torch.save(cifar10_optimizer, 'grad-cifar10-model.pt')"
   ]
  }
 ]
}